网络规模过大时，就可能学到数据中的噪声，常常会导致过拟合。

### 1.正则化

定义dropout率为保留一个神经元为激活状态的概率，那么dropout率越高，正则化程度越低。

高dropout意味着更多神经元是激活的，那么正则化更少。

### 2.Dropout

相当于bagging

**在架构中添加Dropout这一改动会影响训练过程，但是不会影响测试过程**

### 3.Batch normalization

使每一层输入的范围分布大致固定

##### 归一化

一般左机器学习应用时大部分时间都花在特征处理上，其中关键一步就是对特征数据进行归一化。

* 归一化加快了梯度下降求最优解的速度
* 归一化有可能提高精度
* 归一化类型：线性归一化，标准差标准化，非线性归一化
* 减少梯度消失或者梯度爆炸的情况



### 4.扩增数据集



