## SGD随机梯度下降

**描述**：

赋予一个初始值，然后检查跟最佳值的插值，不断迭代调整权重。



### 梯度下降法

* 随机梯度下降（每次使用一个样本）

* 小批量梯度下降（每次用一小批样本算出总损失，因而反向传播的梯度折中）

* 全批量梯度下降（一次性使用全部样本）

  

  这三种方法，对于全体样本的损失函数曲面来说，梯度一个比一个准确。

  

  但是，在工程应用中，受到内存或者IO磁盘的吞吐性能制约，若要最小化梯度下降的实际运算时间，需要在梯度方向准确性和数据传输性能之间取平衡。

  

  **所以，对于数据过大以至于无法在RAM中同时处理时，RAM每次智能装一个样本，选择SGD**